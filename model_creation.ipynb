{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_creation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPs0qEaasv6vg2FwIU+3+Ck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevm4788/Face-emotion-detection/blob/main/model_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbuDZ-r8Iaj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Flatten,Activation\n",
        "from keras import models, layers"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2SRvbN6Bs4j"
      },
      "source": [
        "data=pd.read_csv(\"fer2013.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "3KRGVgjd8PV1",
        "outputId": "b813ecfd-039a-48d0-ed9d-830f490b241e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_v4S92q8WwL",
        "outputId": "c841c521-4821-4d58-d27a-c3c47f5eb48e"
      },
      "source": [
        "data['Usage'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name: Usage, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Z4S_I3SaB7ch",
        "outputId": "bfcccd0b-6199-4e21-fa09-940ff7b802bc"
      },
      "source": [
        "label=[\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\n",
        "sns.countplot(data['emotion'],)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1dc2db810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCK4LkJ0AhN3"
      },
      "source": [
        "def parse_data(data):\n",
        "    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\n",
        "    \n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row,'pixels'], dtype=int, sep=' ')\n",
        "        image = np.reshape(image, (48, 48, 1))\n",
        "        image_array[i] = image\n",
        "        \n",
        "    return image_array, image_label\n",
        "\n",
        "# Splitting the data into train, validation and testing set thanks to Usage column\n",
        "train_images, train_labels = parse_data(data[data[\"Usage\"] == \"Training\"])\n",
        "valid_images, valid_labels = parse_data(data[data[\"Usage\"] == \"PrivateTest\"])\n",
        "test_images, test_labels = parse_data(data[data[\"Usage\"] == \"PublicTest\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIwxw6MxFlz2",
        "outputId": "d65d1b98-42a5-4a12-ec2b-7ab553dc0cb1"
      },
      "source": [
        "data['Usage'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name: Usage, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoX_AmYD8tyk",
        "outputId": "884619ce-487b-44bb-d9d6-a9b5e7ab241a"
      },
      "source": [
        "print(\"train shape\", np.shape(train_images))\n",
        "print(\"validation shape\", np.shape(valid_images))\n",
        "print(\"validation shape\", np.shape(test_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape (28709, 48, 48, 1)\n",
            "validation shape (3589, 48, 48, 1)\n",
            "validation shape (3589, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSe4sOP48nTT"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB013UmL8-Rw"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(48,48,1)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        " \n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uaJMMyN9Ech"
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGx7V0JSWxxa"
      },
      "source": [
        "fitting = model.fit(train_images, train_labels, batch_size=256, epochs=30, verbose=1, \n",
        "                   validation_data =(valid_images, valid_labels)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utH0z9an--_x"
      },
      "source": [
        "def vis_training(hlist, start=1):\n",
        "    \n",
        "    loss = np.concatenate([h.history['loss'] for h in hlist])\n",
        "    val_loss = np.concatenate([h.history['valid_loss'] for h in hlist])\n",
        "    acc = np.concatenate([h.history['accuracy'] for h in hlist])\n",
        "    val_acc = np.concatenate([h.history['valid_accuracy'] for h in hlist])\n",
        "    \n",
        "    epoch_range = range(1,len(loss)+1)\n",
        "\n",
        "    plt.figure(figsize=[12,6])\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epoch_range[start-1:], loss[start-1:], label='Training Loss')\n",
        "    plt.plot(epoch_range[start-1:], val_loss[start-1:], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epoch_range[start-1:], acc[start-1:], label='Training Accuracy')\n",
        "    plt.plot(epoch_range[start-1:], val_acc[start-1:], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r9aIDx4_DYz"
      },
      "source": [
        "vis_training([fitting])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXfLE1zZD9Lf"
      },
      "source": [
        "test_prob = model.predict(test_images)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == test_labels)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlWQ9oSsWRxS"
      },
      "source": [
        "The model was trained and saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ccX8i1L-Nu1"
      },
      "source": [
        "model.save('final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}